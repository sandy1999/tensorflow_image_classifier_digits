{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Image classifier \n",
    "\n",
    "In notebook defines how a convolution neural network can be used to classify Images, MNIST data set is been used for training purpose and we are using tensorflow for making a our Convolution Neural Network. \n",
    "\n",
    "Now you may think Why we are using Convolution Neural Network for our digit classifier, why not `openCV`? Reason is still \n",
    "*CNN* is considered best option for image classifier and gives exceptionally good accuracy as compared to other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "\n",
    "In this section we are going to define our import libraries and other helper libraries for our CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # tensorflow lib \n",
    "\n",
    "# helper library \n",
    "import numpy as np # matrix maths \n",
    "from sklearn.metrics import confusion_matrix # accuracy matrix \n",
    "from datetime import timedelta # for time purpose \n",
    "import math # for math operations \n",
    "import time\n",
    "\n",
    "# plotting libraries \n",
    "import matplotlib.pyplot as plt # to plot \n",
    "# for inline plots \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configration of Neural Network \n",
    "\n",
    "This section defines hyper parameters for our convolution layer which can be used to train and tune our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution layer 1 \n",
    "filter_size1 = 5 # a 5x5 pixel filter in layer 1\n",
    "num_layers1 = 16 # number of filters for layer 1\n",
    "\n",
    "# Convolution layer 2\n",
    "filter_size2 = 5 # a 5x5 pixel filter in layer 2\n",
    "num_layers2 = 36 # number of filters for layer 2\n",
    "\n",
    "# fully connected layer \n",
    "fc_layer = 128 # number of neurons in fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data \n",
    "\n",
    "In this section we are going to load data set for our CNN classifier. \n",
    "\n",
    "Data set consists of pictures of various pictures of digits from MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f70cb47aefa6>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/sanidhya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/sanidhya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sanidhya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sanidhya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sanidhya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# loading data library \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load input data into a data var \n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priniting number of instacnces in train, test and validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train set is 55000\n",
      "Number of images in test set 10000\n",
      "Number of images in validation set is 5000\n"
     ]
    }
   ],
   "source": [
    "# train data \n",
    "print(\"Number of images in train set is {}\".format(len(data.train.labels)))\n",
    "# test data \n",
    "print(\"Number of images in test set {}\".format(len(data.test.labels)))\n",
    "# validation set \n",
    "print(\"Number of images in validation set is {}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class-labels are One-Hot encoded, which means that each label is a vector with 10 elements, all of which are zero except for one element. The index of this one element is the class-number, that is, the digit shown in the associated image. We also need the class-numbers as integers for the test-set, so we calculate it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dimensions \n",
    "\n",
    "There are many places where dimensions would be required in our source code so its the time to define them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size we know that MNIST images are of 28*28 pixels \n",
    "img_size = 28\n",
    "\n",
    "# image size when it is been converted into a one dimensional array.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# making a image shape tuple with attributes as height and width \n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# defining num of color channels \n",
    "# since it is a gray scale which only consists of one channel so \n",
    "num_channel = 1\n",
    "\n",
    "# defining label class i.e 10, each class for each digit.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to plot an image \n",
    "\n",
    "this is a helper function in order to plot a grid of nine images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting a image set form test images \n",
    "images = data.test.images[0:9]\n",
    "\n",
    "# getting classes for these images \n",
    "cls_true = data.test.cls[:9]\n",
    "\n",
    "# using plot function \n",
    "plot_images(images, cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow graph \n",
    "\n",
    "In order to make a convolution we are going to follow our tf graph model to make a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to genrate new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a weights function \n",
    "def add_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a bias function \n",
    "def add_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape = [length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to make a convolution layer 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_convolution_layer(previous_input, # previous layer \n",
    "                          num_input_channel, # number of channles in our images  \n",
    "                          filter_size, # size of filter for this layer \n",
    "                          num_filters, # number of filters for this layer \n",
    "                          use_pooling=True): # use 2 * 2 pooling \n",
    "    # shape of filer weights \n",
    "    shape = [filter_size, filter_size, num_input_channel, num_filters]\n",
    "    \n",
    "    # create a new weights aka filter shape \n",
    "    weights = add_weights(shape=shape)\n",
    "    \n",
    "    # creating biases one of each filter \n",
    "    biases = add_biases(length=num_filters)\n",
    "    \n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=previous_input,\n",
    "                        filter = weights,\n",
    "                        strides = [1, 1, 1, 1],\n",
    "                        padding = 'SAME')\n",
    "    \n",
    "    # adding biases to our layer \n",
    "    layer += biases\n",
    "    \n",
    "    # adding pooling \n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(layer,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # performing reLU operation \n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for making a flattened layer \n",
    "\n",
    "In this function we are going to flatten our layer i.e we are going to convert our layer into one dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flatten_layer(layer):\n",
    "    # get the shape of input layer \n",
    "    layer_shape = layer.get_shape()\n",
    "    \n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # time to reshape and flatten our layer \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to create a fully connected layer\n",
    "\n",
    "\n",
    "\n",
    "This function creates a new fully-connected layer in the computational graph for TensorFlow. Nothing is actually calculated here, we are just adding the mathematical formulas to the TensorFlow graph.\n",
    "\n",
    "It is assumed that the input is a 2-dim tensor of shape [num_images, num_inputs]. The output is a 2-dim tensor of shape [num_images, num_outputs]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function \n",
    "def new_fc_layer(previous_input,\n",
    "                num_inputs,\n",
    "                num_outputs,\n",
    "                use_relu = True):\n",
    "    \n",
    "    # making a new weights \n",
    "    weights = add_weights(shape=[num_inputs, num_outputs])\n",
    "    \n",
    "    # generating new biases \n",
    "    biases = add_biases(length=num_outputs)\n",
    "    \n",
    "    # matrix multiplication \n",
    "    layer = tf.add(biases, tf.matmul(previous_input, weights))\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for images\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size for input\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label placeholder\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-f820441b408d>:2: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# true classes for our labels in one d\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creting first convolution layer \n",
    "conv_layer1, conv_weights1 = new_convolution_layer(x_image, num_input_channel=num_channel, filter_size= filter_size1, \n",
    "                                                  num_filters=num_layers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer2, conv_weights2 = new_convolution_layer(conv_layer1, num_input_channel=num_layers1, filter_size=filter_size2, \n",
    "                                                   num_filters=num_layers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = make_flatten_layer(conv_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features,num_outputs=fc_layer, use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc layer 2 \n",
    "layer_fc2 = new_fc_layer(layer_fc1, num_inputs=fc_layer, num_outputs=num_classes, use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting class number \n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function to be optimized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics \n",
    "\n",
    "We are in need of a performance matrix and techniques in order to make a efficient and optimized model along with the way to show progress to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if correct prediction or not \n",
    "correct_prediction = tf.equal(y_pred_cls,y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate accuracy of a model \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Run \n",
    "\n",
    "Creating a session in order to run a TF garph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init session \n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing graph variables \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to run optimization \n",
    "\n",
    "There are around 55000 images in our training set which can be really cumbersome and time consuming for gradients to be calculated, so we are only going to use a batch of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an optimization function \n",
    "total_iterations = 0\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    \n",
    "    #start time \n",
    "    start_time = time.time()    \n",
    "    \n",
    "    # iterating in num of iterations\n",
    "    for i in range(total_iterations, total_iterations+ num_iterations):\n",
    "        \n",
    "        # getting a batches of images \n",
    "        x_batch, y_true_batch = data.train.next_batch(image_batch_size)\n",
    "        \n",
    "        # making a feed dict \n",
    "        feed_dict = {x:x_batch, y_true:y_true_batch}\n",
    "        \n",
    "        # running a optimizer \n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        # displaying a progress to our users \n",
    "        if i % 100 == 0:\n",
    "            # computing accuracy at that state \n",
    "            acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "            \n",
    "            # message to print\n",
    "            msg = \"Optimization iteration {:>6}, Train Accuracy {}%\"\n",
    "            \n",
    "            # print it \n",
    "            print(msg.format(i+1, acc))\n",
    "            \n",
    "    # update number of iteration \n",
    "    total_iterations += num_iterations\n",
    "    \n",
    "    # end time \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # print time ussage \n",
    "    print(\"Time ussage :\" + str(timedelta(seconds = int(round(end_time - start_time)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test-set into smaller batches of this size.\n",
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # Number of images in the test-set.\n",
    "    num_test = len(data.test.images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        # Get the images from the test-set between index i and j.\n",
    "        images = data.test.images[i:j, :]\n",
    "\n",
    "        # Get the associated labels.\n",
    "        labels = data.test.labels[i:j, :]\n",
    "\n",
    "        # Create a feed-dict with these images and labels.\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = sess.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Convenience variable for the true class-numbers of the test-set.\n",
    "    cls_true = data.test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    # Calculate the number of correctly classified images.\n",
    "    # When summing a boolean array, False means 0 and True means 1.\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    # Classification accuracy is the number of correctly classified\n",
    "    # images divided by the total number of images in the test-set.\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance before optimization \n",
    "\n",
    "Here is the time to show performance before any optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 8.5% (848 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration      1, Train Accuracy 0.171875%\n",
      "Time ussage :0:00:00\n"
     ]
    }
   ],
   "source": [
    "# performance after 1 optimization \n",
    "optimize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.0% (997 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after 100 optimization\n",
    "\n",
    "After 100 optimizations model have significantly improved its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time ussage :0:00:11\n"
     ]
    }
   ],
   "source": [
    "# since we already optimized it once to iterations = 99\n",
    "optimize(num_iterations=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 71.7% (7174 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance accuracy after 1000 optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration    101, Train Accuracy 0.625%\n",
      "Optimization iteration    201, Train Accuracy 0.875%\n",
      "Optimization iteration    301, Train Accuracy 0.90625%\n",
      "Optimization iteration    401, Train Accuracy 0.921875%\n",
      "Optimization iteration    501, Train Accuracy 0.9375%\n",
      "Optimization iteration    601, Train Accuracy 0.90625%\n",
      "Optimization iteration    701, Train Accuracy 0.984375%\n",
      "Optimization iteration    801, Train Accuracy 0.828125%\n",
      "Optimization iteration    901, Train Accuracy 0.859375%\n",
      "Time ussage :0:01:37\n"
     ]
    }
   ],
   "source": [
    "optimize(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 92.7% (9272 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance accuracy after 10000 optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization iteration   1001, Train Accuracy 0.90625%\n",
      "Optimization iteration   1101, Train Accuracy 0.90625%\n",
      "Optimization iteration   1201, Train Accuracy 0.9375%\n",
      "Optimization iteration   1301, Train Accuracy 0.890625%\n",
      "Optimization iteration   1401, Train Accuracy 0.921875%\n",
      "Optimization iteration   1501, Train Accuracy 0.953125%\n",
      "Optimization iteration   1601, Train Accuracy 0.96875%\n",
      "Optimization iteration   1701, Train Accuracy 0.890625%\n",
      "Optimization iteration   1801, Train Accuracy 0.984375%\n",
      "Optimization iteration   1901, Train Accuracy 0.90625%\n",
      "Optimization iteration   2001, Train Accuracy 0.984375%\n",
      "Optimization iteration   2101, Train Accuracy 0.96875%\n",
      "Optimization iteration   2201, Train Accuracy 1.0%\n",
      "Optimization iteration   2301, Train Accuracy 0.96875%\n",
      "Optimization iteration   2401, Train Accuracy 0.984375%\n",
      "Optimization iteration   2501, Train Accuracy 0.953125%\n",
      "Optimization iteration   2601, Train Accuracy 0.953125%\n",
      "Optimization iteration   2701, Train Accuracy 0.953125%\n",
      "Optimization iteration   2801, Train Accuracy 0.921875%\n",
      "Optimization iteration   2901, Train Accuracy 0.96875%\n",
      "Optimization iteration   3001, Train Accuracy 0.984375%\n",
      "Optimization iteration   3101, Train Accuracy 1.0%\n",
      "Optimization iteration   3201, Train Accuracy 0.953125%\n",
      "Optimization iteration   3301, Train Accuracy 0.96875%\n",
      "Optimization iteration   3401, Train Accuracy 0.953125%\n",
      "Optimization iteration   3501, Train Accuracy 1.0%\n",
      "Optimization iteration   3601, Train Accuracy 1.0%\n",
      "Optimization iteration   3701, Train Accuracy 1.0%\n",
      "Optimization iteration   3801, Train Accuracy 0.96875%\n",
      "Optimization iteration   3901, Train Accuracy 0.984375%\n",
      "Optimization iteration   4001, Train Accuracy 0.96875%\n",
      "Optimization iteration   4101, Train Accuracy 1.0%\n",
      "Optimization iteration   4201, Train Accuracy 0.9375%\n",
      "Optimization iteration   4301, Train Accuracy 0.96875%\n",
      "Optimization iteration   4401, Train Accuracy 0.984375%\n",
      "Optimization iteration   4501, Train Accuracy 0.953125%\n",
      "Optimization iteration   4601, Train Accuracy 0.96875%\n",
      "Optimization iteration   4701, Train Accuracy 1.0%\n",
      "Optimization iteration   4801, Train Accuracy 0.96875%\n",
      "Optimization iteration   4901, Train Accuracy 1.0%\n",
      "Optimization iteration   5001, Train Accuracy 1.0%\n",
      "Optimization iteration   5101, Train Accuracy 0.984375%\n",
      "Optimization iteration   5201, Train Accuracy 0.984375%\n",
      "Optimization iteration   5301, Train Accuracy 0.96875%\n",
      "Optimization iteration   5401, Train Accuracy 1.0%\n",
      "Optimization iteration   5501, Train Accuracy 0.984375%\n",
      "Optimization iteration   5601, Train Accuracy 0.984375%\n",
      "Optimization iteration   5701, Train Accuracy 0.984375%\n",
      "Optimization iteration   5801, Train Accuracy 1.0%\n",
      "Optimization iteration   5901, Train Accuracy 1.0%\n",
      "Optimization iteration   6001, Train Accuracy 0.984375%\n",
      "Optimization iteration   6101, Train Accuracy 1.0%\n",
      "Optimization iteration   6201, Train Accuracy 1.0%\n",
      "Optimization iteration   6301, Train Accuracy 0.953125%\n",
      "Optimization iteration   6401, Train Accuracy 0.984375%\n",
      "Optimization iteration   6501, Train Accuracy 0.984375%\n",
      "Optimization iteration   6601, Train Accuracy 0.96875%\n",
      "Optimization iteration   6701, Train Accuracy 0.96875%\n",
      "Optimization iteration   6801, Train Accuracy 0.96875%\n",
      "Optimization iteration   6901, Train Accuracy 0.984375%\n",
      "Optimization iteration   7001, Train Accuracy 0.984375%\n",
      "Optimization iteration   7101, Train Accuracy 1.0%\n",
      "Optimization iteration   7201, Train Accuracy 1.0%\n",
      "Optimization iteration   7301, Train Accuracy 1.0%\n",
      "Optimization iteration   7401, Train Accuracy 0.984375%\n",
      "Optimization iteration   7501, Train Accuracy 1.0%\n",
      "Optimization iteration   7601, Train Accuracy 1.0%\n",
      "Optimization iteration   7701, Train Accuracy 1.0%\n",
      "Optimization iteration   7801, Train Accuracy 0.953125%\n",
      "Optimization iteration   7901, Train Accuracy 1.0%\n",
      "Optimization iteration   8001, Train Accuracy 0.953125%\n",
      "Optimization iteration   8101, Train Accuracy 1.0%\n",
      "Optimization iteration   8201, Train Accuracy 1.0%\n",
      "Optimization iteration   8301, Train Accuracy 0.96875%\n",
      "Optimization iteration   8401, Train Accuracy 1.0%\n",
      "Optimization iteration   8501, Train Accuracy 0.984375%\n",
      "Optimization iteration   8601, Train Accuracy 0.984375%\n",
      "Optimization iteration   8701, Train Accuracy 1.0%\n",
      "Optimization iteration   8801, Train Accuracy 0.984375%\n",
      "Optimization iteration   8901, Train Accuracy 0.96875%\n",
      "Optimization iteration   9001, Train Accuracy 1.0%\n",
      "Optimization iteration   9101, Train Accuracy 0.9375%\n",
      "Optimization iteration   9201, Train Accuracy 0.96875%\n",
      "Optimization iteration   9301, Train Accuracy 1.0%\n",
      "Optimization iteration   9401, Train Accuracy 0.96875%\n",
      "Optimization iteration   9501, Train Accuracy 0.984375%\n",
      "Optimization iteration   9601, Train Accuracy 0.984375%\n",
      "Optimization iteration   9701, Train Accuracy 1.0%\n",
      "Optimization iteration   9801, Train Accuracy 0.953125%\n",
      "Optimization iteration   9901, Train Accuracy 0.984375%\n",
      "Time ussage :0:16:00\n"
     ]
    }
   ],
   "source": [
    "optimize(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 98.6% (9855 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
